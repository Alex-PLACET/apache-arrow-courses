{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# IPC: Streaming & File Formats\n",
    "\n",
    "> **Level:** Intermediate  \n",
    "> **Spec:** [IPC Streaming Format](https://arrow.apache.org/docs/format/Columnar.html#ipc-streaming-format) · [IPC File Format](https://arrow.apache.org/docs/format/Columnar.html#ipc-file-format)  \n",
    "> **PyArrow docs:** [Streaming, serialization and IPC](https://arrow.apache.org/docs/python/ipc.html)\n",
    "\n",
    "## What you will learn\n",
    "\n",
    "1. IPC message wire format: continuation marker, metadata length, metadata, body\n",
    "2. End-of-stream (EOS) marker bytes\n",
    "3. Streaming format vs file format (`ARROW1` magic, footer)\n",
    "4. Random access in file format with `get_batch(i)`\n",
    "5. Compression with lz4 and zstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pyarrow as pa\n",
    "import pyarrow.ipc as ipc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s1",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Streaming Format Wire Layout\n",
    "\n",
    "> **Spec:** [IPC streaming format](https://arrow.apache.org/docs/format/Columnar.html#ipc-streaming-format)\n",
    "\n",
    "Each message follows this layout:\n",
    "```\n",
    "[ 0xFFFFFFFF (4 bytes) ]  ← continuation marker\n",
    "[ metadata_size (int32) ] ← size of Flatbuffers metadata\n",
    "[ metadata bytes ]        ← Flatbuffers Message\n",
    "[ padding to 8-byte alignment ]\n",
    "[ body bytes ]            ← raw buffer data\n",
    "```\n",
    "End-of-stream: `0xFFFFFFFF 0x00000000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "streaming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bytes: 904\n",
      "First 4 bytes (continuation marker): ffffffff  (expect ffffffff)\n",
      "EOS marker at byte offset: 896\n",
      "EOS bytes: ffffffff00000000\n"
     ]
    }
   ],
   "source": [
    "schema = pa.schema([pa.field('x', pa.int32()), pa.field('y', pa.utf8())])\n",
    "batches = [\n",
    "    pa.record_batch({'x': [1,2,3], 'y': ['a','b','c']}, schema=schema),\n",
    "    pa.record_batch({'x': [4,5],   'y': ['d','e']},     schema=schema),\n",
    "    pa.record_batch({'x': [6],     'y': ['f']},         schema=schema),\n",
    "]\n",
    "\n",
    "# Write to an in-memory stream\n",
    "buf = io.BytesIO()\n",
    "writer = ipc.new_stream(buf, schema)\n",
    "for b in batches:\n",
    "    writer.write_batch(b)\n",
    "writer.close()\n",
    "raw = buf.getvalue()\n",
    "\n",
    "print(f'Total bytes: {len(raw)}')\n",
    "print(f'First 4 bytes (continuation marker): {raw[:4].hex()}  (expect ffffffff)')\n",
    "# Find EOS marker\n",
    "eos_idx = raw.rfind(b'\\xff\\xff\\xff\\xff\\x00\\x00\\x00\\x00')\n",
    "print(f'EOS marker at byte offset: {eos_idx}')\n",
    "print(f'EOS bytes: {raw[eos_idx:eos_idx+8].hex()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stream_read",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema: x: int32\n",
      "y: string\n",
      "Batch 0: {'x': [1, 2, 3], 'y': ['a', 'b', 'c']}\n",
      "Batch 1: {'x': [4, 5], 'y': ['d', 'e']}\n",
      "Batch 2: {'x': [6], 'y': ['f']}\n"
     ]
    }
   ],
   "source": [
    "# Read back\n",
    "reader = ipc.open_stream(io.BytesIO(raw))\n",
    "print('Schema:', reader.schema)\n",
    "for i, batch in enumerate(reader):\n",
    "    print(f'Batch {i}: {batch.to_pydict()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s2",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. File Format: Magic Bytes & Footer\n",
    "\n",
    "> **Spec:** [IPC file format](https://arrow.apache.org/docs/format/Columnar.html#ipc-file-format)\n",
    "\n",
    "The file format wraps the streaming format with:\n",
    "- Magic bytes `ARROW1` at start and end\n",
    "- A **footer** (Flatbuffers) at the end recording batch offsets for random access\n",
    "\n",
    "```\n",
    "[ b'ARROW1\\0\\0' ]   ← 8-byte magic\n",
    "[ streaming messages ... ]\n",
    "[ footer bytes ]\n",
    "[ footer length (int32) ]\n",
    "[ b'ARROW1\\0\\0' ]   ← 8-byte magic again\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "file_format",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size       : 1178 bytes\n",
      "Magic (start)   : b'ARROW1'\n",
      "Magic (end -6)  : b'ARROW1'\n",
      "\n",
      "Num record batches: 3\n",
      "Batch[2] directly  : {'x': [6], 'y': ['f']}\n"
     ]
    }
   ],
   "source": [
    "file_buf = io.BytesIO()\n",
    "fwriter = ipc.new_file(file_buf, schema)\n",
    "for b in batches:\n",
    "    fwriter.write_batch(b)\n",
    "fwriter.close()\n",
    "fraw = file_buf.getvalue()\n",
    "\n",
    "print(f'File size       : {len(fraw)} bytes')\n",
    "print(f'Magic (start)   : {fraw[:6]}') \n",
    "print(f'Magic (end -6)  : {fraw[-6:]}')\n",
    "\n",
    "# Random access\n",
    "freader = ipc.open_file(io.BytesIO(fraw))\n",
    "print(f'\\nNum record batches: {freader.num_record_batches}')\n",
    "print(f'Batch[2] directly  : {freader.get_batch(2).to_pydict()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s3",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Compression\n",
    "\n",
    "> **PyArrow docs:** [IPC write options](https://arrow.apache.org/docs/python/generated/pyarrow.ipc.IpcWriteOptions.html)\n",
    "\n",
    "Both `lz4_frame` and `zstd` are supported as body compression codecs.  \n",
    "The codec is recorded in each message's metadata, consumers auto-detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain :    800,442 bytes\n",
      "lz4   :    800,530 bytes  (1.00x smaller)\n",
      "zstd  :    767,258 bytes  (1.04x smaller)\n"
     ]
    }
   ],
   "source": [
    "big_schema = pa.schema([pa.field('v', pa.string())])\n",
    "categories = ['Paris','Montpellier','Toulouse','Angers','Rennes','Nantes','Nice']\n",
    "rng = np.random.default_rng(0)\n",
    "data = [categories[i] for i in rng.integers(0,7, 1_000_000)]\n",
    "big_batch  = pa.record_batch({'v': data}, schema=big_schema)\n",
    "\n",
    "def ipc_file_size(batch, codec=None):\n",
    "    buf = io.BytesIO()\n",
    "    opts = ipc.IpcWriteOptions(compression=codec) if codec else ipc.IpcWriteOptions()\n",
    "    w = ipc.new_file(buf, batch.schema, options=opts)\n",
    "    w.write_batch(batch)\n",
    "    w.close()\n",
    "    return len(buf.getvalue())\n",
    "\n",
    "s_plain = ipc_file_size(big_batch)\n",
    "s_lz4   = ipc_file_size(big_batch, 'lz4')\n",
    "s_zstd  = ipc_file_size(big_batch, 'zstd')\n",
    "\n",
    "print(f'Plain : {s_plain:>10,} bytes')\n",
    "print(f'lz4   : {s_lz4:>10,} bytes  ({s_plain/s_lz4:.2f}x smaller)')\n",
    "print(f'zstd  : {s_zstd:>10,} bytes  ({s_plain/s_zstd:.2f}x smaller)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da0b19",
   "metadata": {},
   "source": [
    "---\n",
    "##  IPC vs C Data Interface\n",
    "\n",
    "| Mechanism | When to use | Copy? | Cross-process? |\n",
    "|-----------|-------------|-------|---------------|\n",
    "| **IPC streaming** | Persist to disk, send over network | Yes (serialise) | Yes |\n",
    "| **IPC file** | Random-access on disk | Yes | Yes |\n",
    "| **C Data Interface** | Same-process, different libraries | **No** | No |\n",
    "\n",
    "> The C Data Interface is covered in depth in notebooks 07."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Format | Use case | Random access | Magic |\n",
    "|--------|----------|--------------|-------|\n",
    "| Streaming | Sockets, pipes, incremental | No | None |\n",
    "| File | Disk, object stores | Yes (`get_batch(i)`) | `ARROW1` |\n",
    "\n",
    "- Messages: `0xFFFFFFFF` continuation + int32 metadata length + Flatbuffers + body\n",
    "- EOS: `0xFFFFFFFF 0x00000000`\n",
    "- Compression: lz4 or zstd per message, recorded in metadata\n",
    "\n",
    "**Next ⏭️** [Extension types](06_extension_types.ipynb): custom types with metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
